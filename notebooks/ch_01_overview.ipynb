{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88bf0d1",
   "metadata": {},
   "source": [
    "# An Overview of Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755b31b",
   "metadata": {},
   "source": [
    "One of the reasons we need efficient distributed computing is that we’re collecting\n",
    "ever more data with a large variety at increasing speeds. The storage systems, data\n",
    "processing and analytics engines that have emerged in the last decade are crucially\n",
    "important to the success of many companies. Interestingly, most “big data” technologies\n",
    "are built for and operated by (data) engineers, that are in charge of data\n",
    "collection and processing tasks. The rationale is to free up data scientists to do\n",
    "what they’re best at. As a data science practitioner you might want to focus on training\n",
    "complex machine learning models, running efficient hyperparameter selection,\n",
    "building entirely new and custom models or simulations, or serving your models to\n",
    "showcase them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cebcd0",
   "metadata": {},
   "source": [
    "At the same time, it might be inevitable to scale these workloads to a compute\n",
    "cluster. To do that, the distributed system of your choice needs to support all of these\n",
    "fine-grained “big compute” tasks, potentially on specialized hardware. Ideally, it also\n",
    "fits into the big data tool chain you’re using and is fast enough to meet your latency\n",
    "requirements. In other words, distributed computing has to be powerful and flexible\n",
    "enough for complex data science workloads — and Ray can help you with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00480805",
   "metadata": {},
   "source": [
    "Python is likely the most popular language for data science today, and it’s certainly\n",
    "the one we find the most useful for our daily work. By now it’s over 30 years old,\n",
    "but has a still growing and active community. The rich [PyData ecosystem](https://\n",
    "pydata.org/) is an essential part of a data scientist’s toolbox. How can you make sure\n",
    "to scale out your workloads while still leveraging the tools you need? That’s a difficult\n",
    "problem, especially since communities can’t be forced to just toss their toolbox, or\n",
    "programming language. That means distributed computing tools for data science\n",
    "have to be built for their existing community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2dc7e",
   "metadata": {},
   "source": [
    "Every chapter of this book has an executable notebook that you can run. If you want run the code while following this chapter, you can run this notebook locally or directly in [Colab](https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb): \n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/maxpumperla/learning_ray/blob/main/notebooks/ch_01_overview.ipynb\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7dd72",
   "metadata": {},
   "source": [
    "For this chapter you need to install the following dependencies. We guide you through each dependency and when you need it later on, but if you're impatient you can install them all right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"ray[rllib, serve, tune]==2.2.0\"\n",
    "! pip install \"pyarrow==10.0.0\"\n",
    "! pip install \"tensorflow>=2.9.0\"\n",
    "! pip install \"transformers>=4.24.0\"\n",
    "! pip install \"pygame==2.1.2\" \"gym==0.25.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2050f",
   "metadata": {},
   "source": [
    "To import utility files for this chapter on Colab you will also have to clone the repo and copy the code files to the base path of the runtime. You don't need to do this if you run the notebook locally, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/maxpumperla/learning_ray\n",
    "%cp -r learning_ray/notebooks/* ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5a63e",
   "metadata": {},
   "source": [
    "## What is Ray?\n",
    "\n",
    "Ray is a great computing framework for the Python data science community because it is flexible and distributed, making it easy to use and understand. It allows you to efficiently parallelize Python programs on your own computer and run them on a cluster without much modification. Additionally, its high-level libraries are easy to set up and can be used together smoothly, and some of them, such as the reinforcement learning library, have a promising future as standalone projects. Even though its core is written in C++, Ray has always been focused on Python and integrates well with many important data science tools. It also has a expanding ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795bed4",
   "metadata": {},
   "source": [
    "Ray is not the first framework for distributed Python, nor will it be the last, but it stands out for its ability to handle custom machine learning tasks with ease. Its various modules work well together, allowing for the flexible execution of complex workloads using familiar Python tools. This book aims to teach how to use Ray to effectively utilize distributed Python for machine learning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba089d",
   "metadata": {},
   "source": [
    "Programming distributed systems can be challenging because it requires specific skills and experience. While these systems are designed to be efficient and allow users to focus on their tasks, they often have [\"leaky abstractions\"](https://www.joelonsoftware.com/2002/11/11/thelaw-of-leaky-abstractions) that can make it difficult to get clusters of computers to work as desired. In addition, many software systems require more resources than a single server can provide, and modern systems need to be able to handle failures and offer high availability. This means that applications may need to run on multiple machines or even in different data centers in order to function reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08256e35",
   "metadata": {},
   "source": [
    "Even if you are not very familiar with machine learning (ML) or artificial intelligence (AI), you have probably heard about recent advances in these fields. Some examples of these advances include Deepmind's Alpha-Fold, which is a system for solving the protein folding problem, and OpenAI's Codex, which helps software developers with the tedious parts of their job. It is commonly known that ML systems require a lot of data to be trained and that ML models tend to become larger. OpenAI has demonstrated that the amount of computing power needed to train AI models has been increasing exponentially, as shown in their paper \"AI and Compute.\" In their study, the operations needed for AI systems were measured in petaflops (thousands of trillion operations per second) and have doubled every 3.4 months since 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a010dd",
   "metadata": {},
   "source": [
    "While Moore's Law suggests that computer transistors will double every two years, the use of distributed computing in machine learning can significantly increase the speed at which tasks are completed. While distributed computing may be seen as challenging, it would be beneficial to develop abstractions that allow for code to run on clusters without constantly considering individual machines and their interactions. By focusing specifically on AI workloads, it may be possible to make distributed computing more accessible and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1fcd87",
   "metadata": {},
   "source": [
    "Researchers at RISELab at UC Berkeley developed Ray to improve the efficiency of their workloads by distributing them. These workloads were flexible in nature and did not fit into existing frameworks. Ray was also designed to handle the distribution of the work and allow researchers to focus on their work without worrying about the specifics of their compute cluster. It was created with a focus on high-performance and diverse workloads, and allows researchers to use their preferred Python tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28aaa68",
   "metadata": {},
   "source": [
    "### Design Philosophy\n",
    "\n",
    "Ray was created with a focus on certain design principles. Its API aims to be straightforward and applicable to a wide range of situations, while the compute model is designed to be adaptable. Additionally, the system architecture is optimized for speed and the ability to handle increasing workloads. Let's delve into these points further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dea857",
   "metadata": {},
   "source": [
    "#### Simplicity and abstraction\n",
    "\n",
    "Ray's API is not only simple to use, but it is also intuitive and easy to learn, as you will see in Chapter 2. Whether you want to use all the CPU cores on your laptop or leverage all the machines in your cluster, you can do so with minimal changes to your code. Ray handles task distribution and coordination behind the scenes, allowing you to focus on your work rather than worrying about the mechanics of distributed computing. Additionally, the API is very flexible and can easily be integrated with other tools. For example, Ray actors can interact with other distributed Python workloads, making it a useful \"glue code\" for connecting different systems and frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f1f1a",
   "metadata": {},
   "source": [
    "#### Flexibility and heterogeneity\n",
    "\n",
    "Ray's API is created to allow users to easily write flexible and modular code for artificial intelligence tasks, especially those involving reinforcement learning. As long as the workload can be expressed in Python, it can be distributed using Ray. However, it is important to ensure that sufficient resources are available and to consider what should be distributed. Ray does not impose any limitations on what can be done with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83621e6c",
   "metadata": {},
   "source": [
    "Ray is able to handle a variety of different computational tasks. For example, when working on a complex simulation, it is common for there to be different steps that take different amounts of time to complete. Some may take a long time while others only take a few milliseconds. Ray is able to efficiently schedule and execute these tasks, even if they need to be run in parallel. Additionally, Ray's framework allows for dynamic execution, which is helpful when subsequent tasks depend on the outcome of an earlier task. Overall, Ray provides flexibility in managing heterogeneous workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637aa16",
   "metadata": {},
   "source": [
    "It is important to be able to adapt your resource usage and Ray allows for the use of different types of hardware. For example, certain tasks may require the use of a GPU while others may perform better on a CPU. Ray gives you the ability to choose the most appropriate hardware for each task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752190b",
   "metadata": {},
   "source": [
    "#### Speed and scalability\n",
    "\n",
    "One of the key features of Ray is its speed. It can handle millions of tasks per second with minimal latency, making it an efficient choice for distributed systems. Additionally, Ray is effective at distributing and scheduling tasks across a compute cluster, and it does so in a way that is fault-tolerant. Its auto-scaler can adjust the number of machines in the cluster to match current demand, which helps to minimize costs and ensure there are enough resources available to run workloads. In the event of failures, Ray is designed to recover quickly, further contributing to its overall speed. While we will delve into the specifics of Ray's architecture later on, for now, let's focus on how it can be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf37d6",
   "metadata": {},
   "source": [
    "### Core, Libraries and Ecosystem\n",
    "\n",
    "Now that you are aware of the purpose and goals behind the creation of Ray, let's examine the three layers of the system. While there may be other ways to classify these layers, the approach used in this book is the most logical and understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe95e4",
   "metadata": {},
   "source": [
    "1. A low-level, distributed computing framework for Python with a concise core API and tooling for cluster deployment called Ray Core.\n",
    "2. A set of high-level libraries for built and maintained by the creators of Ray. This includes the so-called Ray AI Runtime (AIR) to use these libraries with a unified API in common machine learning workloads.\n",
    "3. A growing ecosystem of integrations and partnerships with other notable\n",
    "projects, which span many aspects of the first two layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45267d",
   "metadata": {},
   "source": [
    "There are several layers to explore in this chapter. The core of Ray's engine, with its API at the center, serves as the foundation for everything else. The data science libraries in Ray build on top of this core and offer a specialized interface. Many data scientists will use these libraries directly, while those working in ML or platform engineering may focus on creating tools that extend the Ray Core API. Ray AIR serves as a connector between the various Ray libraries and provides a consistent framework for handling common AI tasks. Additionally, there are a increasing number of third-party integrations available for Ray that can be utilized by experienced practitioners. We will examine each of these layers in more detail.\n",
    "\n",
    "Below is a quick preview of what libraries and integrations each layer consists of. Maybe you already spot a few of your favorite tools from the ecosystem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551fa5c",
   "metadata": {},
   "source": [
    "![Ray Layers](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ray_layers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4462377",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## A framework for distributed computing\n",
    "\n",
    "At its core, Ray is a distributed computing framework.\n",
    "We'll  provide you with just the basic terminology here, and talk about Ray's\n",
    "architecture in depth in chapter 2.\n",
    "In short, Ray sets up and manages clusters of computers so that you can run\n",
    "distributed tasks on them.\n",
    "A ray cluster consists of nodes that are connected to each other via a network.\n",
    "You program against the so-called _driver_, the program root, which lives on\n",
    "the _head node_.\n",
    "The driver can run _jobs_, that is a collection of tasks, that are run on the nodes\n",
    "in the cluster.\n",
    "Specifically, the individual tasks of a job are run on _worker_ processes on\n",
    "worker nodes_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c2640",
   "metadata": {},
   "source": [
    "![Ray cluster](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/simple_cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668e1ae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "What's interesting is that a Ray cluster can also be a _local cluster_, i.e. a cluster\n",
    "consisting just of your own computer.\n",
    "In this case, there's just one node, namely the head node, which has the driver\n",
    "process and some worker processes.\n",
    "\n",
    "With that knowledge at hand, it's time to get your hands dirty and run your first\n",
    "local Ray cluster.\n",
    "Installing Ray on any of the major operating systems should work seamlessly\n",
    "using `pip`:\n",
    "\n",
    "```\n",
    "pip install \"ray[rllib, tune, serve]==2.2.0\"\n",
    "```\n",
    "\n",
    "With a simple `pip install ray` you would have installed just the very basics of Ray.\n",
    "Since we want to explore some advanced features, we installed the \"extras\" `rllib`\n",
    "and `tune`, which we'll discuss in a bit.\n",
    "Depending on your system configuration you may not need the quotation marks in the\n",
    "above installation command.\n",
    "\n",
    "Next, go ahead and start a Python session.\n",
    "You could use the `ipython` interpreter, which I find to be the most suitable\n",
    "environment for following along simple examples.\n",
    "The choice is up to you, but in any case please remember to use Python version\n",
    "`3.7` or later.\n",
    "In your Python session you can now easily import and initialize Ray as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29d6ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:05:02,372\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.2.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.9.13', ray_version='2.2.0', ray_commit='b6af0887ee5f2e460202133791ad941a41f15beb', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-12-20_10-04-56_546341_41438/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-12-20_10-04-56_546341_41438/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-12-20_10-04-56_546341_41438', 'metrics_export_port': 65335, 'gcs_address': '127.0.0.1:65519', 'address': '127.0.0.1:65519', 'dashboard_agent_listen_port': 52365, 'node_id': 'd8c4216b824bd6cf8e2a6f92685843205d2cb012a1df4ec3f73710eb'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de3a35",
   "metadata": {},
   "source": [
    "By running those two lines of code, you have set up a Ray cluster on your local machine. This cluster can take advantage of all the cores on your computer as worker processes. Currently, your Ray cluster isn't doing much, but that will change in the following section. The init function used to initiate the cluster is one of just six fundamental API calls that you will delve into in Chapter 2. Overall, the Ray Core API is straightforward and easy to use, but since it is also a lower-level interface, it takes time to create more complex examples with it. Chapter 2 includes a detailed first example to introduce you to the Ray Core API, and in Chapter 3 you will see how to build a more advanced Ray application for reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfedfee",
   "metadata": {},
   "source": [
    "In the above example, you did not provide any arguments when calling the `ray.init(...)` function. If you wanted to use Ray on a real cluster, you would need to include more arguments in this init call, which is known as the Ray Client. The Ray Client is used to connect to an existing Ray cluster and interact with it. If you are interested in learning more about using the Ray Client to connect to your production clusters, you can refer to the [Ray documentation](https://docs.ray.io/en/latest/cluster/ray-client.html). Keep in mind that working with compute clusters can be complex, and there are many options for deploying Ray applications on them. For example, you can use cloud providers like AWS, GCP, or Azure to host your Ray clusters, or you can set up your own hardware or use tools like Kubernetes. We will revisit the topic of scaling workloads with Ray Clusters in Chapter 9, after discussing some specific applications of Ray in earlier chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616cab30",
   "metadata": {},
   "source": [
    "Before moving on the Ray’s higher level libraries, let’s briefly summarize the two\n",
    "foundational components of Ray as a distributed computation framework:\n",
    "\n",
    "- _Ray Clusters_: This component is in charge of allocating resources, creating nodes,\n",
    "and ensuring they are healthy. A good way to get started with Ray Clusters is its\n",
    "dedicated quick start guide (https://docs.ray.io/en/latest/cluster/quickstart.html).\n",
    "- _Ray Core_: Once your cluster is up and running, you use the Ray Core API\n",
    "that to program against it. You can get started with Ray Core by following the\n",
    "official walk-through (https://docs.ray.io/en/latest/ray-core/walkthrough.html) for\n",
    "this component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c684724",
   "metadata": {},
   "source": [
    "## Ray's Libraries\n",
    "\n",
    "In this section, we will introduce the data science libraries included with Ray. To understand how these libraries can be beneficial to you, it's important to first have a general understanding of what data science entails. With this context in mind, you'll be able to see how Ray's higher-level libraries fit into the larger picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5e6fb",
   "metadata": {},
   "source": [
    "### Ray AIR and the Data Science Workflow\n",
    "\n",
    "The concept of \"data science\" (DS) has undergone significant changes in recent years, and you can find various definitions of the term online, some more useful than others. However, we believe that data science is the practice of using data to gain insights and develop practical applications. It is a field that involves building and understanding things, and is therefore quite practical and applied. In this sense, calling practitioners of this field \"data scientists\" is similar to calling hackers \"computer scientists\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c96d8",
   "metadata": {},
   "source": [
    "Data science involves a series of steps that involve identifying and gathering the necessary data, processing it, creating models, and implementing solutions. While machine learning may be a part of this process, it is not always necessary. If machine learning is included, there may be additional steps involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925fab2",
   "metadata": {},
   "source": [
    "- _Data Processing_: To use machine learning effectively, you must prepare the data in a way that the ML model can understand. This process, called feature engineering, involves selecting and transforming the data that will be input into the model. It can be a challenging task, so it is helpful to have access to reliable tools to assist with it.\n",
    "- _Model Training_: For machine learning, it is necessary to train your algorithms on data that has been previously processed. This involves selecting the appropriate algorithm for the task at hand. Having a diverse range of algorithms to choose from can also be beneficial.\n",
    "- _Hyperparameter Tuning_: During the process of training a machine learning model, certain parameters can be fine-tuned in order to improve its performance. In addition to these model parameters, there are also hyperparameters that can be adjusted before training begins. The proper adjustment of these hyperparameters can significantly impact the effectiveness of the final machine learning model. Fortunately, there are tools available to assist with the process of optimizing these hyperparameters.\n",
    "- _Model Serving_: The deployment of trained models is necessary in order to provide access to them for those who need it. This process, known as serving a model, involves making it available through various means, such as using simple HTTP servers in prototypes or specialized software packages specifically designed for serving ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f2d2d",
   "metadata": {},
   "source": [
    "It is important to note that this list is not exhaustive and there is more to consider when building machine learning applications. Nonetheless, it is undeniable that these four steps are critical for the success of a data science project that utilizes machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9d3a9",
   "metadata": {},
   "source": [
    "![Data Science Workflow](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ds_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d395aa2",
   "metadata": {},
   "source": [
    "Ray has created dedicated libraries for each of the four ML-specific steps mentioned earlier. These libraries include Ray Datasets for data processing, Ray Train for distributed model training, Ray RLlib for reinforcement learning workloads, Ray Tune for efficient hyperparameter tuning, and Ray Serve for serving models. It is important to note that all of these libraries are distributed by design, as that is how Ray is built."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faef52c",
   "metadata": {},
   "source": [
    "Additionally, it is important to consider that these steps are usually not completed separately but rather as part of a larger process. It is beneficial to have all relevant libraries working smoothly together and to have a uniform API throughout the data science process. The Ray AI Runtime (AIR) was designed with this in mind, providing a common runtime and API for experiments and the capability to expand workloads as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b40b5e9",
   "metadata": {},
   "source": [
    "![Ray AIR](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/AIR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9918c5a",
   "metadata": {},
   "source": [
    "In this chapter, we will not be discussing the Ray AI Runtime API in depth (more on that can be found in Chapter 10). However, we can provide an overview of the components that contribute to it. Specifically, we will go through each of the DS libraries that make up Ray one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312e12f",
   "metadata": {},
   "source": [
    "### Ray Data\n",
    "The first high-level library of Ray we talk about is called \"Ray Data\".\n",
    "This library contains a data structure aptly called `Dataset`, a multitude of\n",
    "connectors for loading data from various formats and systems,\n",
    "an API for transforming such datasets, a way to build data processing pipelines\n",
    "with them, and many integrations with other data processing frameworks.\n",
    "The `Dataset` abstraction builds on the powerful\n",
    "[Arrow framework](https://arrow.apache.org/).\n",
    "\n",
    "To use Ray Data, you need to install Arrow for Python, for instance by running\n",
    "`pip install pyarrow`.\n",
    "We'll now discuss a simple example that creates a distributed `Dataset` on your\n",
    "local Ray cluster from a Python data structure.\n",
    "Specifically, you'll create a dataset from a Python dictionary containing a\n",
    "string `name` and an integer-valued `data` for `10000` entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121d832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '0', 'data': 0}\n",
      "{'name': '1', 'data': 1}\n",
      "{'name': '2', 'data': 2}\n",
      "{'name': '3', 'data': 3}\n",
      "{'name': '4', 'data': 4}\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "items = [{\"name\": str(i), \"data\": i} for i in range(10000)]\n",
    "ds = ray.data.from_items(items)\n",
    "ds.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c95752b",
   "metadata": {},
   "source": [
    "Great, now you have some rows, but what can you do with that data?\n",
    "The `Dataset` API bets heavily on functional programming, as it is very well suited\n",
    "for data transformations.\n",
    "Even though Python 3 made a point of hiding some of its functional programming\n",
    "capabilities, you're probably\n",
    "familiar with functionality such as `map`, `filter` and others.\n",
    "If not, it's easy enough to pick up.\n",
    "`map` takes each element of your dataset and transforms is into something\n",
    "else, in parallel.\n",
    "`filter` removes data points according to a boolean filter function.\n",
    "And the slightly more elaborate `flat_map` first maps values similarly to `map`,\n",
    "but then also \"flattens\" the result.\n",
    "For instance, if `map` would produce a list of lists, `flat_map` would flatten out\n",
    "the nested lists and give\n",
    "you just a list.\n",
    "Equipped with these three functional API calls, let's see how easily you can\n",
    "transform your dataset `ds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e008dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:05:43,431\tWARNING dataset.py:4233 -- The `map`, `flat_map`, and `filter` operations are unvectorized and can be very slow. Consider using `.map_batches()` instead.\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:01<00:00, 139.83it/s]\n",
      "Filter: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 1144.95it/s]\n",
      "Flat_Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 1193.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 4, 64, 16, 4096, 36, 46656, 64, 262144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "squares = ds.map(lambda x: x[\"data\"] ** 2)\n",
    "\n",
    "evens = squares.filter(lambda x: x % 2 == 0)\n",
    "evens.count()\n",
    "\n",
    "cubes = evens.flat_map(lambda x: [x, x**3])\n",
    "sample = cubes.take(10)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e42ee9",
   "metadata": {},
   "source": [
    "The drawback of `Dataset` transformations is that each step gets executed\n",
    "synchronously.\n",
    "In the above example this is a non-issue, but for complex tasks that e.g. mix\n",
    "reading files and processing data,\n",
    "you want an execution that can overlap the individual tasks.\n",
    "`DatasetPipeline` does exactly that.\n",
    "Let's rewrite the last example into a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc16601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:05:49,790\tINFO dataset.py:3693 -- Created DatasetPipeline with 20 windows: 7390b min, 8000b max, 7944b mean\n",
      "2022-12-20 10:05:49,791\tINFO dataset.py:3703 -- Blocks per window: 10 min, 10 max, 10 mean\n",
      "2022-12-20 10:05:49,793\tWARNING dataset.py:3715 -- ⚠️  This pipeline's parallelism is limited by its blocks per window to ~10 concurrent tasks per window. To maximize performance, increase the blocks per window to at least 12. This may require increasing the base dataset's parallelism and/or adjusting the windowing parameters.\n",
      "2022-12-20 10:05:49,794\tINFO dataset.py:3742 -- ✔️  This pipeline's windows likely fit in object store memory without spilling.\n",
      "Stage 0:   0%|                                                                                                                                                                                                   | 0/20 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                                                                                                                            | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Stage 1:   5%|█████████▎                                                                                                                                                                                 | 1/20 [00:00<00:01,  9.56it/s]\u001B[A\n",
      "Stage 0:  10%|██████████████████▋                                                                                                                                                                        | 2/20 [00:00<00:00, 18.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "4\n",
      "64\n",
      "16\n",
      "4096\n",
      "36\n",
      "46656\n",
      "64\n",
      "262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = ds.window()\n",
    "result = pipe\\\n",
    "    .map(lambda x: x[\"data\"] ** 2)\\\n",
    "    .filter(lambda x: x % 2 == 0)\\\n",
    "    .flat_map(lambda x: [x, x**3])\n",
    "result.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf7fd1",
   "metadata": {},
   "source": [
    "While there is much more that can be explored regarding Ray Datasets and its integration with certain data processing systems, we will have to postpone a more thorough discussion until Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12db60f0",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Next, we will examine the distributed training abilities of Ray through two libraries. The first library is specifically for reinforcement learning, while the second library is primarily focused on supervised learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a3296",
   "metadata": {},
   "source": [
    "### RL with Ray RLlib\n",
    "\n",
    "We will begin with discussing Ray RLlib for reinforcement learning, a library that utilizes either TensorFlow or PyTorch as its underlying machine learning framework. Both of these frameworks are highly compatible with each other, so you can use whichever one you prefer without sacrificing much in terms of functionality. In this book, we will provide examples using both TensorFlow and PyTorch to give you a comprehensive understanding of how to use Ray with either framework. In this chapter we'll work with TensorFlow, which you can install by simply running the command \"pip install tensorflow\" in your terminal. If you wanted to, you could equally well install PyTorch instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88c28e",
   "metadata": {},
   "source": [
    "RLlib provides a command line tool called `rllib` that can be easily used to run examples. It was already installed when you ran \"pip install 'ray[rllib]'\" earlier. While you will primarily use the Python API for more advanced examples in Chapter 4, this tool allows you to quickly try out RL experiments using RLlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a7dbc",
   "metadata": {},
   "source": [
    "We will consider a classic control problem in which we try to balance a pole on a cart. Imagine that the pole is attached to the cart at a joint and is subject to the force of gravity. The cart is able to move along a frictionless track and we can give it a push to the left or right with a fixed force. If we do this properly, the pole should remain upright. For each time step in which the pole does not fall, we receive a reward of 1. Our goal is to collect as many rewards as possible and we want to see if we can use a reinforcement learning algorithm to help us achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5432ed",
   "metadata": {},
   "source": [
    "![Cartpole Env](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/cartpole.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7c019",
   "metadata": {},
   "source": [
    "Our goal is to train a reinforcement learning agent that can perform two actions: pushing to the left or to the right, observe the consequences of these actions, and learn from the experience to maximize the reward. To achieve this using Ray RLlib, we can utilize a \"tuned example,\" which is a pre-set algorithm that works effectively for a specific problem. These examples can be easily run with a single command and RLlib offers a variety of them, which can be viewed by using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dc3c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[3m                                 RLlib Examples                                 \u001B[0m\r\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃\u001B[1m \u001B[0m\u001B[1mExample ID                     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mDescription                               \u001B[0m\u001B[1m \u001B[0m┃\r\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-a2c                      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns grid search over several Atari games \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mon A2C.                                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-dqn                      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun grid search on Atari environments with\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mDQN.                                      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-duel-ddqn                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun grid search on Atari environments with\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mduelling double DQN.                      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-impala                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun grid search over several atari games  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwith IMPALA.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-ppo                      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun grid search over several atari games  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwith PPO.                                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36matari-sac                      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun grid search on several atari games    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwith SAC.                                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mbreakout-apex-dqn              \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns Apex DQN on BreakoutNoFrameskip-v4.  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mbreakout-ddppo                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPPO on BreakoutNoFrameskip-v4.     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-a2c                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns A2C on the CartPole-v1 environment.  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-a2c-micro             \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns A2C on the CartPole-v1 environment,  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35musing micro-batches.                      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-a3c                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns A3C on the CartPole-v1 environment.  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-alpha-zero            \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns AlphaZero on a Cartpole with sparse  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mrewards.                                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-apex-dqn              \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns Apex DQN on CartPole-v1.             \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-appo                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on CartPole-v1.                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-ars                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns ARS on CartPole-v1.                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-bc                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns BC on CartPole-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-crr                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun CRR on CartPole-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-ddppo                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPPO on CartPole-v1                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-dqn                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun DQN on CartPole-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-dt                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun DT on CartPole-v1.                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-es                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun ES on CartPole-v1.                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-impala                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun IMPALA on CartPole-v1.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-maml                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MAML on CartPole-v1.                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-marwil                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MARWIL on CartPole-v1.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-mbmpo                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MBMPO on a CartPole environment       \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwrapper.                                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-pg                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PG on CartPole-v1                     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-ppo                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on CartPole-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-sac                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SAC on CartPole-v1                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mcartpole-simpleq               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SimpleQ on CartPole-v1                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mdm-control-dreamer             \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun DREAMER on a suite of control problems\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mby Deepmind.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mfrozenlake-appo                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on FrozenLake-v1.               \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-appo               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on HalfCheetah-v2.              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-bullet-ddpg        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPG on HalfCheetahBulletEnv-v0.     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-cql                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns grid search on HalfCheetah           \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35menvironments with CQL.                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-ddpg               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPG on HalfCheetah-v2.              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-maml               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MAML on a custom HalfCheetah          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35menvironment.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-mbmpo              \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MBMPO on a HalfCheetah environment    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwrapper.                                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-ppo                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on HalfCheetah-v2.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhalfcheetah-sac                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SAC on HalfCheetah-v3.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhopper-bullet-ddpg             \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPG on HopperBulletEnv-v0.          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhopper-cql                     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns grid search on Hopper environments   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwith CQL.                                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhopper-mbmpo                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MBMPO on a Hopper environment wrapper.\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhopper-ppo                     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on Hopper-v1.                     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhumanoid-es                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun ES on Humanoid-v2.                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mhumanoid-ppo                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on Humanoid-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36minverted-pendulum-td3          \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun TD3 on InvertedPendulum-v2.           \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmountaincar-apex-ddpg          \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns Apex DDPG on                         \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mMountainCarContinuous-v0.                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmountaincar-ddpg               \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPG on MountainCarContinuous-v0.    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmujoco-td3                     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun TD3 against four of the hardest MuJoCo\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mtasks.                                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmulti-agent-cartpole-alpha-star\u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns AlphaStar on 4 CartPole agents.      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmulti-agent-cartpole-appo      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on RLlib's MultiAgentCartPole   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mmulti-agent-cartpole-impala    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun IMPALA on RLlib's MultiAgentCartPole  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpacman-sac                     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SAC on MsPacmanNoFrameskip-v4.        \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-apex-ddpg             \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns Apex DDPG on Pendulum-v1.            \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-appo                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on Pendulum-v1.                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-cql                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns CQL on Pendulum-v1.                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-crr                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun CRR on Pendulum-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-ddpg                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPG on Pendulum-v1.                 \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-ddppo                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns DDPPO on Pendulum-v1.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-dt                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun DT on Pendulum-v1.                    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-impala                \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun IMPALA on Pendulum-v1.                \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-maml                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MAML on a custom Pendulum environment.\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-mbmpo                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun MBMPO on a Pendulum environment       \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mwrapper.                                  \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-ppo                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on Pendulum-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-sac                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SAC on Pendulum-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpendulum-td3                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun TD3 on Pendulum-v1.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-a3c                       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns A3C on the PongDeterministic-v4      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35menvironment.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-apex-dqn                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns Apex DQN on PongNoFrameskip-v4.      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-appo                      \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns APPO on PongNoFrameskip-v4.          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-dqn                       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun DQN on PongDeterministic-v4.          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-impala                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun IMPALA on PongNoFrameskip-v4.         \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-ppo                       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on PongNoFrameskip-v4.            \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mpong-rainbow                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun Rainbow on PongDeterministic-v4.      \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrecsys-bandits                 \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns BanditLinUCB on a Recommendation     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mSimulation environment.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrecsys-long-term-slateq        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun SlateQ on a recommendation system     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35maimed at long-term satisfaction.          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrecsys-parametric-slateq       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mSlateQ run on a recommendation system.    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrecsys-ppo                     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on a recommender system example   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mfrom RLlib.                               \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrecsys-slateq                  \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mSlateQ run on a recommendation system.    \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mrepeatafterme-ppo              \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on RLlib's RepeatAfterMe          \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35menvironment.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mstateless-cartpole-r2d2        \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun R2D2 on a stateless cart pole         \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35menvironment.                              \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mswimmer-ars                    \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRuns ARS on Swimmer-v2.                   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mtwo-step-game-maddpg           \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun RLlib's Two-step game with multi-agent\u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m                                 \u001B[0m│\u001B[35m \u001B[0m\u001B[35mDDPG.                                     \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mtwo-step-game-qmix             \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun QMIX on RLlib's two-step game.        \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "│\u001B[36m \u001B[0m\u001B[36mwalker2d-ppo                   \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35mRun PPO on the Walker2d-v1 environment.   \u001B[0m\u001B[35m \u001B[0m│\r\n",
      "└─────────────────────────────────┴────────────────────────────────────────────┘\r\n",
      "Run any RLlib example as using \u001B[32m'rllib example run \u001B[0m\u001B[32m<\u001B[0m\u001B[32mExample\u001B[0m\u001B[32m ID\u001B[0m\u001B[32m>\u001B[0m\u001B[32m'\u001B[0m.See \u001B[32m'rllib \u001B[0m\r\n",
      "\u001B[32mexample run --help'\u001B[0m for more information.\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! rllib example list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1aae96",
   "metadata": {},
   "source": [
    "An example that is available is called cartpole-ppo, which utilizes the PPO algorithm to solve the cartpole problem in the CartPole-v1 environment from OpenAI Gym (https://gymnasium.farama.org/environments/classic_control/cart_pole/). You can access the configuration of this example by entering `rllib example get cartpole-ppo` in the command line. This will first download the example file from GitHub and then display the configuration, which is written in YAML format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d5a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Attempting to download example file https://raw.githubusercontent.com/ray-project/ray/master/rllib/tuned_examples/ppo/cartpole-ppo.yaml...\n",
      "b'cartpole-ppo:\\n    env: CartPole-v1\\n    run: PPO\\n    stop:\\n        episode_reward_mean: 150\\n        timesteps_total: 100000\\n    config:\\n        # Works for both torch and tf.\\n        framework: tf\\n        gamma: 0.99\\n        lr: 0.0003\\n        num_workers: 1\\n        observation_filter: MeanStdFilter\\n        num_sgd_iter: 6\\n        vf_loss_coeff: 0.01\\n        model:\\n            fcnet_hiddens: [32]\\n            fcnet_activation: linear\\n            vf_share_layers: true\\n        enable_connectors: true\\n'\n",
      "  Status code: 200\n",
      "  Downloaded example file to /var/folders/y_/l41py1sx7bl5n30jygrsv0q40000gn/T/tmpnobuu1ka.yaml\n",
      "cartpole-ppo:\n",
      "    env: CartPole-v1\n",
      "    run: PPO\n",
      "    stop:\n",
      "        episode_reward_mean: \u001B[1;36m150\u001B[0m\n",
      "        timesteps_total: \u001B[1;36m100000\u001B[0m\n",
      "    config:\n",
      "        # Works for both torch and tf.\n",
      "        framework: tf\n",
      "        gamma: \u001B[1;36m0.99\u001B[0m\n",
      "        lr: \u001B[1;36m0.0003\u001B[0m\n",
      "        num_workers: \u001B[1;36m1\u001B[0m\n",
      "        observation_filter: MeanStdFilter\n",
      "        num_sgd_iter: \u001B[1;36m6\u001B[0m\n",
      "        vf_loss_coeff: \u001B[1;36m0.01\u001B[0m\n",
      "        model:\n",
      "            fcnet_hiddens: \u001B[1m[\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1m]\u001B[0m\n",
      "            fcnet_activation: linear\n",
      "            vf_share_layers: true\n",
      "        enable_connectors: true\n",
      "\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "! rllib example get cartpole-ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923a2fe",
   "metadata": {},
   "source": [
    "While the specific details of the configuration file are not relevant at this time, it is important to note that you must include the Cartpole-v1 environment and the necessary RL configuration for the training process to function properly. You do not need any special equipment to run this configuration, and it should only take a few minutes to complete. In order to train this example, you will need to install the PyGame dependency by using the command `pip install pygame`, and then simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rllib example run cartpole-ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968bbd12",
   "metadata": {},
   "source": [
    "If you run this, RLlib creates a named experiment and logs important metrics such as\n",
    "the reward, or the `episode_reward_mean` for you. In the output of the training run,\n",
    "you should also see information about the machine (`loc`, meaning host name and\n",
    "port), as well as the status of your training runs. If your run is `TERMINATED`, but you’ve\n",
    "never seen a successfully `RUNNING` experiment in the log, something must have gone\n",
    "wrong. Here’s a sample snippet of a training run:\n",
    "\n",
    "```{text}\n",
    "+-----------------------------+----------+----------------+\n",
    "| Trial name | status | loc |\n",
    "|-----------------------------+----------+----------------|\n",
    "| PPO_CartPole-v0_9931e_00000 | RUNNING | 127.0.0.1:8683 |\n",
    "+-----------------------------+----------+----------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc646f",
   "metadata": {},
   "source": [
    "When the training run finishes and things went well, you should see the following\n",
    "output:\n",
    "\n",
    "```{text}\n",
    "Your training finished.\n",
    "Best available checkpoint for each trial:\n",
    "<checkpoint-path>/checkpoint_<number>\n",
    "\n",
    "You can now evaluate your trained algorithm from any checkpoint,\n",
    "e.g. by running:\n",
    "\n",
    "╭─────────────────────────────────────────────────────────────────────────╮\n",
    "│ rllib evaluate <checkpoint-path>/checkpoint_<number> --algo PPO         │\n",
    "╰─────────────────────────────────────────────────────────────────────────╯\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d054d",
   "metadata": {},
   "source": [
    "Your local Ray checkpoint folder is `~/ray-results` by default. For the training\n",
    "configuration we used, your `<checkpoint-path>` should be of the form \n",
    "`~/ray_results/cartpole-ppo/PPO_CartPole-v1_<experiment_id>`. During training\n",
    "procedure, your intermediate and final model checkpoints get generated into this\n",
    "folder.\n",
    "\n",
    "To evaluate the performance of your trained RL algorithm, you can now evaluate it\n",
    "from checkpoint by copying the command the previous example training run printed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a631a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rllib evaluate <checkpoint-path>/checkpoint_<number> --algo PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e553bda",
   "metadata": {},
   "source": [
    "Executing this command will display the rewards obtained by the RL algorithm you trained in the `CartPole-v1` environment. There is a lot more that can be done with RLlib, which will be discussed further in Chapter 4. The purpose of this example was to demonstrate how easy it is to begin using RLlib and the `rllib` command line tool through the use of the example and evaluate commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa244c",
   "metadata": {},
   "source": [
    "#### Ray Train\n",
    "\n",
    "If you are interested in using Ray for supervised learning, rather than just reinforcement learning, you can use the Ray Train library. However, we do not have enough expertise with frameworks like TensorFlow to provide a detailed example of how to use Ray Train at this time. If you want to learn more about distributed training, you can move on to Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35125e",
   "metadata": {},
   "source": [
    "### Ray Tune\n",
    "Naming things is hard, but the Ray team hit the spot with _Ray Tune_, which you can\n",
    "use to tune all\n",
    "sorts of parameters.\n",
    "Specifically, it was built to find good hyperparameters for machine learning models.\n",
    "The typical setup is as follows:\n",
    "\n",
    "- You want to run an extremely computationally expensive training function. In ML it's not uncommon\n",
    "  to run training procedures that take days, if not weeks, but let's say you're dealing with just a couple of minutes.\n",
    "- As result of training, you compute a so-called objective function. Usually you either want to maximize\n",
    "  your gains or minimize your losses in terms of performance of your experiment.\n",
    "- The tricky bit is that your training function might depend on certain parameters,\n",
    "  hyperparameters, that influence the value of your objective function.\n",
    "- You may have a hunch what individual hyperparameters should be, but tuning them all can be difficult.\n",
    "  Even if you can restrict these parameters to a sensible range, it's usually prohibitive to test a wide\n",
    "  range of combinations. Your training function is simply too expensive.\n",
    "\n",
    "What can you do to efficiently sample hyperparameters and get \"good enough\" results on your objective?\n",
    "The field concerned with solving this problem is called _hyperparameter optimization_ (HPO), and Ray Tune has\n",
    "an enormous suite of algorithms for tackling it.\n",
    "Let's look at a first example of Ray Tune used for the situation we just explained.\n",
    "The focus is yet again on Ray and its API, and not on a specific ML task (which we simply simulate for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d05c4f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-12-20 10:12:03</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:32.62        </td></tr>\n",
       "<tr><td>Memory:      </td><td>18.1/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/12.03 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">   x</th><th style=\"text-align: right;\">   y</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_4a371_00000</td><td>TERMINATED</td><td>127.0.0.1:42585</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0019</td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>training_function_4a371_00001</td><td>TERMINATED</td><td>127.0.0.1:42588</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0041</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00002</td><td>TERMINATED</td><td>127.0.0.1:42589</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0009</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
       "<tr><td>training_function_4a371_00003</td><td>TERMINATED</td><td>127.0.0.1:42594</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0019</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00004</td><td>TERMINATED</td><td>127.0.0.1:42595</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0038</td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>training_function_4a371_00005</td><td>TERMINATED</td><td>127.0.0.1:42596</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0049</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00006</td><td>TERMINATED</td><td>127.0.0.1:42597</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0006</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
       "<tr><td>training_function_4a371_00007</td><td>TERMINATED</td><td>127.0.0.1:42598</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0045</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
       "<tr><td>training_function_4a371_00008</td><td>TERMINATED</td><td>127.0.0.1:42599</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0016</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
       "<tr><td>training_function_4a371_00009</td><td>TERMINATED</td><td>127.0.0.1:42600</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0055</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00010</td><td>TERMINATED</td><td>127.0.0.1:42601</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0053</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
       "<tr><td>training_function_4a371_00011</td><td>TERMINATED</td><td>127.0.0.1:42602</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.001 </td><td style=\"text-align: right;\">0.353553</td></tr>\n",
       "<tr><td>training_function_4a371_00012</td><td>TERMINATED</td><td>127.0.0.1:42585</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0029</td><td style=\"text-align: right;\">0       </td></tr>\n",
       "<tr><td>training_function_4a371_00013</td><td>TERMINATED</td><td>127.0.0.1:42595</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0044</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
       "<tr><td>training_function_4a371_00014</td><td>TERMINATED</td><td>127.0.0.1:42596</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0054</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
       "<tr><td>training_function_4a371_00015</td><td>TERMINATED</td><td>127.0.0.1:42588</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0045</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00016</td><td>TERMINATED</td><td>127.0.0.1:42598</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0047</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
       "<tr><td>training_function_4a371_00017</td><td>TERMINATED</td><td>127.0.0.1:42597</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0044</td><td style=\"text-align: right;\">0.353553</td></tr>\n",
       "<tr><td>training_function_4a371_00018</td><td>TERMINATED</td><td>127.0.0.1:42601</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0051</td><td style=\"text-align: right;\">0.5     </td></tr>\n",
       "<tr><td>training_function_4a371_00019</td><td>TERMINATED</td><td>127.0.0.1:42600</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0033</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00020</td><td>TERMINATED</td><td>127.0.0.1:42602</td><td style=\"text-align: right;\">-1  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0022</td><td style=\"text-align: right;\">1       </td></tr>\n",
       "<tr><td>training_function_4a371_00021</td><td>TERMINATED</td><td>127.0.0.1:42599</td><td style=\"text-align: right;\">-0.5</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0043</td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00022</td><td>TERMINATED</td><td>127.0.0.1:42589</td><td style=\"text-align: right;\"> 0  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0034</td><td style=\"text-align: right;\">0.707107</td></tr>\n",
       "<tr><td>training_function_4a371_00023</td><td>TERMINATED</td><td>127.0.0.1:42594</td><td style=\"text-align: right;\"> 0.5</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.005 </td><td style=\"text-align: right;\">0.790569</td></tr>\n",
       "<tr><td>training_function_4a371_00024</td><td>TERMINATED</td><td>127.0.0.1:42585</td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\"> 1  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.0043</td><td style=\"text-align: right;\">1       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>experiment_tag       </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">   score</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>training_function_4a371_00000</td><td>2022-12-20_10-11-43</td><td>True  </td><td>                </td><td>494ed1a59d494bc6ba4760cbe8657871</td><td>0_x=-1,y=-1          </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42585</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0019</td><td style=\"text-align: right;\">           10.0019</td><td style=\"text-align: right;\">       10.0019</td><td style=\"text-align: right;\"> 1671527503</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00000</td><td style=\"text-align: right;\">   0.00247288</td></tr>\n",
       "<tr><td>training_function_4a371_00001</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>b9bf7326ef8b476dbedd8df0c7f34f73</td><td>1_x=-0.5000,y=-1     </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42588</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0041</td><td style=\"text-align: right;\">           10.0041</td><td style=\"text-align: right;\">       10.0041</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00001</td><td style=\"text-align: right;\">   0.0415869 </td></tr>\n",
       "<tr><td>training_function_4a371_00002</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>a4efaf055d5c4bdf8b03404e0fd2bc34</td><td>2_x=0,y=-1           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42589</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0009</td><td style=\"text-align: right;\">           10.0009</td><td style=\"text-align: right;\">       10.0009</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00002</td><td style=\"text-align: right;\">   0.030731  </td></tr>\n",
       "<tr><td>training_function_4a371_00003</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>2a144f96ed2a4e8ab45e404c3b978e7b</td><td>3_x=0.5000,y=-1      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42594</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0019</td><td style=\"text-align: right;\">           10.0019</td><td style=\"text-align: right;\">       10.0019</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00003</td><td style=\"text-align: right;\">   0.0482671 </td></tr>\n",
       "<tr><td>training_function_4a371_00004</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>86caff41ea4349d9899ab098d96626c9</td><td>4_x=1,y=-1           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42595</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0038</td><td style=\"text-align: right;\">           10.0038</td><td style=\"text-align: right;\">       10.0038</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00004</td><td style=\"text-align: right;\">   0.010777  </td></tr>\n",
       "<tr><td>training_function_4a371_00005</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>ef976c7e3f9845299c91f579117b872f</td><td>5_x=-1,y=-0.5000     </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42596</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0049</td><td style=\"text-align: right;\">           10.0049</td><td style=\"text-align: right;\">       10.0049</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00005</td><td style=\"text-align: right;\">   0.0338681 </td></tr>\n",
       "<tr><td>training_function_4a371_00006</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>2f2885ae2c744505a1ec68f43fbe9ede</td><td>6_x=-0.5000,y=-0.5000</td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42597</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0006</td><td style=\"text-align: right;\">           10.0006</td><td style=\"text-align: right;\">       10.0006</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00006</td><td style=\"text-align: right;\">   0.0315561 </td></tr>\n",
       "<tr><td>training_function_4a371_00007</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>a5091dce37d342a2b6af5fa1fbecdbf4</td><td>7_x=0,y=-0.5000      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42598</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0045</td><td style=\"text-align: right;\">           10.0045</td><td style=\"text-align: right;\">       10.0045</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00007</td><td style=\"text-align: right;\">   0.030849  </td></tr>\n",
       "<tr><td>training_function_4a371_00008</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>d8f205e32fbc4666a32aa1ec410c29d0</td><td>8_x=0.5000,y=-0.5000 </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42599</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0016</td><td style=\"text-align: right;\">           10.0016</td><td style=\"text-align: right;\">       10.0016</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00008</td><td style=\"text-align: right;\">   0.038857  </td></tr>\n",
       "<tr><td>training_function_4a371_00009</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>9efc9400e11341b08a1eb705830ae780</td><td>9_x=1,y=-0.5000      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42600</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0055</td><td style=\"text-align: right;\">           10.0055</td><td style=\"text-align: right;\">       10.0055</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00009</td><td style=\"text-align: right;\">   0.00727797</td></tr>\n",
       "<tr><td>training_function_4a371_00010</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>eebcc54cdc334cbf981f4688b3808a3b</td><td>10_x=-1,y=0          </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42601</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0053</td><td style=\"text-align: right;\">           10.0053</td><td style=\"text-align: right;\">       10.0053</td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00010</td><td style=\"text-align: right;\">   0.02653   </td></tr>\n",
       "<tr><td>training_function_4a371_00011</td><td>2022-12-20_10-11-47</td><td>True  </td><td>                </td><td>5bf52487723542b596e3e48a3bb3e08d</td><td>11_x=-0.5000,y=0     </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42602</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.001 </td><td style=\"text-align: right;\">           10.001 </td><td style=\"text-align: right;\">       10.001 </td><td style=\"text-align: right;\"> 1671527507</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00011</td><td style=\"text-align: right;\">   0.0319781 </td></tr>\n",
       "<tr><td>training_function_4a371_00012</td><td>2022-12-20_10-11-53</td><td>True  </td><td>                </td><td>494ed1a59d494bc6ba4760cbe8657871</td><td>12_x=0,y=0           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42585</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">             10.0029</td><td style=\"text-align: right;\">           10.0029</td><td style=\"text-align: right;\">       10.0029</td><td style=\"text-align: right;\"> 1671527513</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00012</td><td style=\"text-align: right;\">   0.00247288</td></tr>\n",
       "<tr><td>training_function_4a371_00013</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>86caff41ea4349d9899ab098d96626c9</td><td>13_x=0.5000,y=0      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42595</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0044</td><td style=\"text-align: right;\">           10.0044</td><td style=\"text-align: right;\">       10.0044</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00013</td><td style=\"text-align: right;\">   0.010777  </td></tr>\n",
       "<tr><td>training_function_4a371_00014</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>ef976c7e3f9845299c91f579117b872f</td><td>14_x=1,y=0           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42596</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0054</td><td style=\"text-align: right;\">           10.0054</td><td style=\"text-align: right;\">       10.0054</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00014</td><td style=\"text-align: right;\">   0.0338681 </td></tr>\n",
       "<tr><td>training_function_4a371_00015</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>b9bf7326ef8b476dbedd8df0c7f34f73</td><td>15_x=-1,y=0.5000     </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42588</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0045</td><td style=\"text-align: right;\">           10.0045</td><td style=\"text-align: right;\">       10.0045</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00015</td><td style=\"text-align: right;\">   0.0415869 </td></tr>\n",
       "<tr><td>training_function_4a371_00016</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>a5091dce37d342a2b6af5fa1fbecdbf4</td><td>16_x=-0.5000,y=0.5000</td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42598</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0047</td><td style=\"text-align: right;\">           10.0047</td><td style=\"text-align: right;\">       10.0047</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00016</td><td style=\"text-align: right;\">   0.030849  </td></tr>\n",
       "<tr><td>training_function_4a371_00017</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>2f2885ae2c744505a1ec68f43fbe9ede</td><td>17_x=0,y=0.5000      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42597</td><td style=\"text-align: right;\">0.353553</td><td style=\"text-align: right;\">             10.0044</td><td style=\"text-align: right;\">           10.0044</td><td style=\"text-align: right;\">       10.0044</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00017</td><td style=\"text-align: right;\">   0.0315561 </td></tr>\n",
       "<tr><td>training_function_4a371_00018</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>eebcc54cdc334cbf981f4688b3808a3b</td><td>18_x=0.5000,y=0.5000 </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42601</td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">             10.0051</td><td style=\"text-align: right;\">           10.0051</td><td style=\"text-align: right;\">       10.0051</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00018</td><td style=\"text-align: right;\">   0.02653   </td></tr>\n",
       "<tr><td>training_function_4a371_00019</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>9efc9400e11341b08a1eb705830ae780</td><td>19_x=1,y=0.5000      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42600</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0033</td><td style=\"text-align: right;\">           10.0033</td><td style=\"text-align: right;\">       10.0033</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00019</td><td style=\"text-align: right;\">   0.00727797</td></tr>\n",
       "<tr><td>training_function_4a371_00020</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>5bf52487723542b596e3e48a3bb3e08d</td><td>20_x=-1,y=1          </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42602</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0022</td><td style=\"text-align: right;\">           10.0022</td><td style=\"text-align: right;\">       10.0022</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00020</td><td style=\"text-align: right;\">   0.0319781 </td></tr>\n",
       "<tr><td>training_function_4a371_00021</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>d8f205e32fbc4666a32aa1ec410c29d0</td><td>21_x=-0.5000,y=1     </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42599</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.0043</td><td style=\"text-align: right;\">           10.0043</td><td style=\"text-align: right;\">       10.0043</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00021</td><td style=\"text-align: right;\">   0.038857  </td></tr>\n",
       "<tr><td>training_function_4a371_00022</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>a4efaf055d5c4bdf8b03404e0fd2bc34</td><td>22_x=0,y=1           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42589</td><td style=\"text-align: right;\">0.707107</td><td style=\"text-align: right;\">             10.0034</td><td style=\"text-align: right;\">           10.0034</td><td style=\"text-align: right;\">       10.0034</td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00022</td><td style=\"text-align: right;\">   0.030731  </td></tr>\n",
       "<tr><td>training_function_4a371_00023</td><td>2022-12-20_10-11-57</td><td>True  </td><td>                </td><td>2a144f96ed2a4e8ab45e404c3b978e7b</td><td>23_x=0.5000,y=1      </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42594</td><td style=\"text-align: right;\">0.790569</td><td style=\"text-align: right;\">             10.005 </td><td style=\"text-align: right;\">           10.005 </td><td style=\"text-align: right;\">       10.005 </td><td style=\"text-align: right;\"> 1671527517</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00023</td><td style=\"text-align: right;\">   0.0482671 </td></tr>\n",
       "<tr><td>training_function_4a371_00024</td><td>2022-12-20_10-12-03</td><td>True  </td><td>                </td><td>494ed1a59d494bc6ba4760cbe8657871</td><td>24_x=1,y=1           </td><td>mac       </td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">42585</td><td style=\"text-align: right;\">1       </td><td style=\"text-align: right;\">             10.0043</td><td style=\"text-align: right;\">           10.0043</td><td style=\"text-align: right;\">       10.0043</td><td style=\"text-align: right;\"> 1671527523</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                   1</td><td>4a371_00024</td><td style=\"text-align: right;\">   0.00247288</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 10:12:03,528\tINFO tune.py:762 -- Total run time: 33.58 seconds (32.61 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 0, 'y': 0}\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def training_function(config):\n",
    "    x, y = config[\"x\"], config[\"y\"]\n",
    "    time.sleep(10)\n",
    "    score = objective(x, y)\n",
    "    tune.report(score=score)\n",
    "\n",
    "\n",
    "def objective(x, y):\n",
    "    return math.sqrt((x**2 + y**2)/2)\n",
    "\n",
    "\n",
    "result = tune.run(\n",
    "    training_function,\n",
    "    config={\n",
    "        \"x\": tune.grid_search([-1, -.5, 0, .5, 1]),\n",
    "        \"y\": tune.grid_search([-1, -.5, 0, .5, 1])\n",
    "    })\n",
    "\n",
    "print(result.get_best_config(metric=\"score\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e790e45",
   "metadata": {},
   "source": [
    "Note how the output of this run is structurally similar to what you’ve\n",
    "seen in the RLlib example. That’s no coincidence, as RLlib (like many other Ray\n",
    "libraries) uses Ray Tune under the hood. If you look closely, you will see `PENDING`\n",
    "runs that wait for execution, as well as `RUNNING` and `TERMINATED` runs. Tune takes care\n",
    "of selecting, scheduling, and executing your training runs for you automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f30412",
   "metadata": {},
   "source": [
    "This Tune example aims to identify the optimal values for parameters x and y for a training_function with the goal of minimizing a particular objective. Although the objective function may seem complicated as it involves calculating the sum of the squares of x and y, all of the values will be non-negative. Therefore, the lowest value is achieved when x and y are both equal to 0, resulting in an evaluation of 0 for the objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3298b6",
   "metadata": {},
   "source": [
    "We do a so-called grid search over all possible parameter combinations. As we explicitly\n",
    "pass in five possible values for both x and y that’s a total of 25 combinations\n",
    "that get fed into the training function. These combinations are evaluated through the training function, which includes a 10 second sleep time. Without Ray's ability to parallelize the process, testing all of these combinations would take more than four minutes. However, on my laptop, this experiment only takes around 35 seconds to complete. The duration may vary depending on the device used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cab1adf",
   "metadata": {},
   "source": [
    "If each training run took several hours, and there were 20 hyperparameters to consider instead of just two, it would not be practical to use grid search. This is especially true if you do not have a good idea of what range the parameters should be in. In these cases, you will need to use more advanced HPO methods like those offered by Ray Tune, which we will discuss in Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b0c80",
   "metadata": {},
   "source": [
    "### Ray Serve\n",
    "\n",
    "The last of Ray's high-level libraries we'll discuss specializes on model serving and is simply called _Ray Serve_.\n",
    "To see an example of it in action, you need a trained ML model to serve.\n",
    "Luckily, nowadays you can find many interesting models on the internet that have already been trained for you.\n",
    "For instance, _Hugging Face_ has a variety of models available for you to download directly in Python.\n",
    "The model we'll use is a language model called _GPT-2_ that takes text as input and produces text to\n",
    "continue or complete the input.\n",
    "For example, you can prompt a question and GPT-2 will try to complete it.\n",
    "\n",
    "Serving such a model is a good way to make it accessible.\n",
    "You may not now how to load and run a TensorFlow model on your computer, but you do now how\n",
    "to ask a question in plain English.\n",
    "Model serving hides the implementation details of a solution and lets users focus on providing\n",
    "inputs and understanding outputs of a model.\n",
    "\n",
    "To proceed, make sure to run `pip install transformers` to install the Hugging Face library\n",
    "that has the model we want to use.\n",
    "With that we can now import and start an instance of Ray's `serve` library, load and deploy a GPT-2\n",
    "model and ask it for the meaning of life, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bb8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import serve\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "\n",
    "serve.start()\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "def model(request):\n",
    "    language_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "    query = request.query_params[\"query\"]\n",
    "    return language_model(query, max_length=100)\n",
    "\n",
    "\n",
    "model.deploy()\n",
    "\n",
    "query = \"What's the meaning of life?\"\n",
    "response = requests.get(f\"http://localhost:8000/model?query={query}\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65135823",
   "metadata": {},
   "source": [
    "In Chapter 9, you will be taught how to correctly implement models in various situations. However, for now, I recommend that you experiment with this example and try different queries. If you repeatedly run the last two lines of code, you will get practically different answers every time. Here is a poetic statement that I queried on my computer, which has been slightly edited for younger readers:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071a0c9",
   "metadata": {},
   "source": [
    "```{text}\n",
    "[{\n",
    "\"generated_text\": \"What's the meaning of life?\\n\\n\n",
    "Is there one way or another of living?\\n\\n\n",
    "How does it feel to be trapped in a relationship?\\n\\n\n",
    "How can it be changed before it's too late?\n",
    "What did we call it in our time?\\n\\n\n",
    "Where do we fit within this world and what are we going to live for?\\n\\n\n",
    "My life as a person has been shaped by the love I've received from others.\"\n",
    "}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab453063",
   "metadata": {},
   "source": [
    "This is the end of our overview of the data science libraries within the second layer of Ray. These libraries, which we have discussed in this chapter, are all based on the Ray Core API. It is fairly simple to create new extensions for Ray, and there are a few more that we are unable to cover in this book. For example, the Ray Workflows library (https://docs.ray.io/en/latest/workflows/index.html) allows users to define and run long-term applications using Ray. Before we conclude this chapter, let's briefly examine the third layer of Ray, which is the expanding ecosystem surrounding the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a41a",
   "metadata": {},
   "source": [
    "## The Ray Ecosystem\n",
    "\n",
    "Ray's libraries are powerful and should be discussed in more detail in the book. Although they are very useful for data science work, we don't want to give the impression that they are the only thing you need from now on. The most successful frameworks are those that work well with other solutions and ideas. It is better to concentrate on your strengths and use other tools to fill any gaps in your solution, which Ray does well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b073dd4",
   "metadata": {},
   "source": [
    "Throughout the book, we will be discussing various libraries that have been built on top of Ray. Additionally, Ray has integrations with existing tools like Spark, Dask, and Pandas. For instance, you can use Ray Datasets, a data loading and compute library, with your existing project that utilizes data processing engines like Spark or Dask. Additionally, you can run the entire Dask ecosystem on a Ray cluster with the Dask-on-Ray scheduler or use the Spark on Ray project to integrate your Spark workloads with Ray. The Modin project also offers a distributed replacement for Pandas dataframes that utilizes Ray or Dask as the distributed execution engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba65e3",
   "metadata": {},
   "source": [
    "Ray's approach is to integrate with various tools rather than trying to replace them, while still providing access to its own native library called Ray Datasets. This will be explored in more detail later in Chapter 11. It's noteworthy that many of the Ray libraries have the ability to seamlessly integrate with other tools as backends, often by creating common interfaces rather than establishing new standards. These interfaces enable you to perform tasks in a distributed manner, something that many of the backends may not offer or may not offer to the same degree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e88155",
   "metadata": {},
   "source": [
    "For example, Ray RLlib and Train both utilize the capabilities of TensorFlow and PyTorch. Additionally, Ray Tune allows for the use of a variety of HPO tools, such as Hyperopt, Optuna, Nevergrad, Ax, and SigOpt, among others. These tools are not automatically distributed, but Tune brings them together in a unified interface for distributed tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7279b0",
   "metadata": {},
   "source": [
    "![Ray Layers](https://raw.githubusercontent.com/maxpumperla/learning_ray/main/notebooks/images/chapter_01/ray_layers.png)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
